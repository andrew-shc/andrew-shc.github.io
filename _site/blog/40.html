<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-11-29">

<title>Interesting Topics For November</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-969ddfa49e00a70eb3423444dbc81f6c.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-443a8c2d8fa65f4c6b846c90aafe8287.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-30fc45633b0910a22497ea642fc28e10.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-443a8c2d8fa65f4c6b846c90aafe8287.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#computer-graphics" id="toc-computer-graphics" class="nav-link" data-scroll-target="#computer-graphics">Computer Graphics</a>
  <ul class="collapse">
  <li><a href="#path-space-differentiable-rendering-psdr" id="toc-path-space-differentiable-rendering-psdr" class="nav-link" data-scroll-target="#path-space-differentiable-rendering-psdr">Path-space differentiable rendering (PSDR)</a></li>
  <li><a href="#geometric-rendering-black-holes" id="toc-geometric-rendering-black-holes" class="nav-link" data-scroll-target="#geometric-rendering-black-holes">Geometric rendering: black holes</a></li>
  <li><a href="#rendering-exotic-light-sources-cold-cathode-fluorescent-displays-ccfds" id="toc-rendering-exotic-light-sources-cold-cathode-fluorescent-displays-ccfds" class="nav-link" data-scroll-target="#rendering-exotic-light-sources-cold-cathode-fluorescent-displays-ccfds">Rendering exotic light sources: cold-cathode fluorescent displays (CCFDs)</a></li>
  <li><a href="#stochastic-geometry" id="toc-stochastic-geometry" class="nav-link" data-scroll-target="#stochastic-geometry">Stochastic geometry</a></li>
  <li><a href="#re-formulating-problems-as-light-transport" id="toc-re-formulating-problems-as-light-transport" class="nav-link" data-scroll-target="#re-formulating-problems-as-light-transport">Re-formulating problems as light-transport</a></li>
  </ul></li>
  <li><a href="#d-vision" id="toc-d-vision" class="nav-link" data-scroll-target="#d-vision">3D Vision</a>
  <ul class="collapse">
  <li><a href="#neural-3d-reconstructiongeneration" id="toc-neural-3d-reconstructiongeneration" class="nav-link" data-scroll-target="#neural-3d-reconstructiongeneration">Neural 3D Reconstruction/Generation</a></li>
  <li><a href="#diffusion-models-stochastic-differential-equations-sdes" id="toc-diffusion-models-stochastic-differential-equations-sdes" class="nav-link" data-scroll-target="#diffusion-models-stochastic-differential-equations-sdes">Diffusion Models &amp; Stochastic Differential Equations (SDEs)</a></li>
  <li><a href="#bundle-adjustment-ba-lie-algebra" id="toc-bundle-adjustment-ba-lie-algebra" class="nav-link" data-scroll-target="#bundle-adjustment-ba-lie-algebra">Bundle Adjustment (BA) &amp; Lie Algebra</a></li>
  <li><a href="#fast-fourier-transform-fft" id="toc-fast-fourier-transform-fft" class="nav-link" data-scroll-target="#fast-fourier-transform-fft">Fast Fourier Transform (FFT)</a></li>
  <li><a href="#applications-of-3d-vision-graphics" id="toc-applications-of-3d-vision-graphics" class="nav-link" data-scroll-target="#applications-of-3d-vision-graphics">Applications of 3D Vision + Graphics</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Interesting Topics For November</h1>
<p class="subtitle lead">General</p>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 29, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>It‚Äôs always good to occasionally take a step back among the hustle and bustle, recalibrate your sense of direction, find new interesting questions to answer, and reflect the progress made from the past year. This blog aims to fossilize my interests at this time for me to potentially start a project from several of these and look back on, and maybe of interest for you too for whatever reason it may be. Note: this is more of an unorganized thought dump.</p>
<p>More computer graphics than 3D vision:</p>
<ul>
<li>Path-space differentiable rendering</li>
<li>Geometric rendering: black holes</li>
<li>Rendering exotic light sources: cold-cathode displays</li>
<li>Stochastic Geometry</li>
<li>Re-formulating problems as light-transport problems: Inverse rendering, walk-on-stars</li>
</ul>
<p>More 3D vision than computer graphics:</p>
<ul>
<li>Neural 3D Reconstruction/Generation: VGGT, 3DGS, Diffusion</li>
<li>Diffusion models &amp; stochastic differential equations (SDEs)</li>
<li>Bundle Adjustment &amp; Lie Algebra</li>
<li>Fast fourier transform (FFT)</li>
<li>Applications of 3D Vision + graphics: Robotics, Perception, Reinforcement Learning</li>
</ul>
</section>
<section id="computer-graphics" class="level1 page-columns page-full">
<h1>Computer Graphics</h1>
<section id="path-space-differentiable-rendering-psdr" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="path-space-differentiable-rendering-psdr">Path-space differentiable rendering (PSDR)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../img/blog/40_pbdr_teaser.png" class="img-fluid figure-img"></p>
<figcaption>Image from a course on physics-based differentiable rendering</figcaption>
</figure>
</div>
<p>In rendering, we take a description of a virtual 3D scene and have the renderer produce a 2D image of it given a camera location and orientation. More specifically, a scene has geometry (e.g., meshes, radiance fields) and light sources (or else the image would just be dark) where the renderer merely records the incoming radiance onto an image. So, an image is merely a record of the more complete virtual 3D scene that is easily transferred and displayed without needing to know the complicated underlying scene (e.g., *.ply files) and executing resource-intensive rendering process (e.g., GPUs). In fact, an image is not limited to recording virtual scenes, but it can also record real-life scenes where we usually don‚Äôt know the underlying complex environment (e.g., given a photo of a mountain, what is the geometry of the mountain?)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. This is where it gets interesting and how PSDR comes into play. Check <a href="#re-formulating-problems-as-light-transport">the other section</a> to see how PSDR is used in this context.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;But remember, a visual record needs light to mediate the underlying complex scene information. (Think exposure time: darker scenes needs longer time to capture the same amount of light to produce a sufficient visual record of a scene, whereas brighter scenes just needs shorter time. If a scene is completely dark, you can think of it needing infinite amount of time to produce an equal quality of a photo.)</p></div></div><p>In forward rendering, there are mostly two common methods: rasterization and path tracing (and a mix of both). If we formalize these rendering process as a function, we get <span class="math inline">\(I=f(\theta)\)</span>, where <span class="math inline">\(I\)</span> is the final image, <span class="math inline">\(\theta\)</span> is the scene parameters (e.g., geometry, cameras), and <span class="math inline">\(f\)</span> is the rendering process. What if we can differentiate it? Like <span class="math inline">\(I=\frac{d}{d\theta}f(\theta)\)</span>? Actually, this question is not too far-fetched in that machine learning has revolutionized in how we model intelligent-like behaviors and optimization, and <em>differentiability</em> is the core idea that enables such learning to take place.</p>
<p>We will be focusing on the more physically-plausible path tracing (via path-integral formulation). In this form, differentiating the rendering process produces two terms: interior term and boundary term. You can read more about them on <span class="citation" data-cites="Zhang:2020:PSDR"><a href="#ref-Zhang:2020:PSDR" role="doc-biblioref">[1]</a></span>, but basically interior term is what we are mainly differentiating against and the boundary term is an important term that accounts for visibility changes, which commonly appears when we differentiate against geometry.</p>
<div class="no-row-height column-margin column-container"></div><p>This is why differentiation with respect to the geometry are messy and complicated. For geometric reconstruction, the shapes can change, inducing a visibility changes on a rendered image. For estimating camera pose, same thing: potential visibility changes. For moving geometries, same visibility changes. And what do we mean by visibilty changes anyways? When some geometry goes in front of another, we have an occlusion of the geometry in the back. These changes happen on <em>discontinuities</em>, making the differentiation hard. Hence, there‚Äôs a lot of current actively-explored topics on computing the derivatives in these fundamental areas.</p>
<p>Another important categories of parameter that we differentiate against are colors. More precisely, emission strength of light sources and the modulation by BSDF. No geometry means easier interior term and no boundary term, but that doesn‚Äôt mean it is easier.. overall. Sometimes, the light sources have small areas or the BSDF is highly-specular. In these cases, sampling becomes important and there are many active topics in this regards (e.g., variance reduction).</p>
<p>Original paper on PSDR: <span class="citation" data-cites="Zhang:2020:PSDR"><a href="#ref-Zhang:2020:PSDR" role="doc-biblioref">[1]</a></span></p>
<div class="no-row-height column-margin column-container"><div id="ref-Zhang:2020:PSDR" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">C. Zhang, B. Miller, K. Yan, I. Gkioulekas, and S. Zhao, <span>‚ÄúPath-space differentiable rendering,‚Äù</span> <em>ACM Trans. Graph.</em>, vol. 39, no. 4, pp. 143:1‚Äì143:19, 2020.</div>
</div></div><p>There are other interesting questions on generalizing PSDR to different rendering processes and geometries:</p>
<ul>
<li>Participating Media: <span class="citation" data-cites="Zhang:2021:PSDR"><a href="#ref-Zhang:2021:PSDR" role="doc-biblioref">[2]</a></span></li>
<li>Volume Rendering: <span class="citation" data-cites="Yu:2023:PSDR-Vol2"><a href="#ref-Yu:2023:PSDR-Vol2" role="doc-biblioref">[3]</a></span></li>
<li><em>other cool stuff‚Ä¶</em></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="ref-Zhang:2021:PSDR" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">C. Zhang, Z. Yu, and S. Zhao, <span>‚ÄúPath-space differentiable rendering of participating media,‚Äù</span> <em>ACM Trans. Graph.</em>, vol. 40, no. 4, pp. 76:1‚Äì76:15, 2021.</div>
</div><div id="ref-Yu:2023:PSDR-Vol2" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Z. Yu, C. Zhang, O. Maury, C. Hery, Z. Dong, and S. Zhao, <span>‚ÄúEfficient path-space differentiable volume rendering with respect to shapes,‚Äù</span> <em>Computer Graphics Forum</em>, vol. 42, no. 4, 2023.</div>
</div><div id="ref-zeng2025surveyphysicsbaseddifferentiablerendering" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Y. Zeng, G. Cai, and S. Zhao, <span>‚ÄúA survey on physics-based differentiable rendering.‚Äù</span> 2025. Available: <a href="https://arxiv.org/abs/2504.01402">https://arxiv.org/abs/2504.01402</a></div>
</div></div><p>Survey paper: <span class="citation" data-cites="zeng2025surveyphysicsbaseddifferentiablerendering"><a href="#ref-zeng2025surveyphysicsbaseddifferentiablerendering" role="doc-biblioref">[4]</a></span></p>
<p>Topics I need to focus more on üòÑ:</p>
<ul>
<li>Reparamaterizations</li>
<li>Sampling theory</li>
<li>Implementing those scary differentiated version of those algorithms, especially when re-formulating it in terms of OptiX.</li>
</ul>
</section>
<section id="geometric-rendering-black-holes" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="geometric-rendering-black-holes">Geometric rendering: black holes</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExaHF1dm9ocWQyN2lvdnJtYXZtc25wbnc0eHB0MjA5ejR2dzFlYXk1ZSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/SVCSsoKU5v6ZJLk07n/giphy.gif" class="img-fluid figure-img"></p>
<figcaption><em>Interstellar</em> (2014)</figcaption>
</figure>
</div>
<p>When I mean geometric rendering, I specifically mean geometrically interesting light transport. Usually, rendering has always just been straight line, which serves majority of the purposes. And when we generalize the theory of light transport, we usually talk about wave <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> and quantum optics, according to <span class="citation" data-cites="veachthesis"><a href="#ref-veachthesis" role="doc-biblioref">[5]</a></span>, which is still just straight lines. Yes, mirrors, caustics, and diffraction does make it more interesting, but they still bend at a single point, not continuously. One thing pops up in my mind whenever I think of a light ray that continuously bends: black holes. Their force is so strong that it warps the light rays continuously, not just bend it at a single point.</p>
<!-- ![[image link](https://rantonels.github.io/starless)](https://rantonels.github.io/starless/pics/bhscattersmall.png) -->
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;The dissertation mentioned how diffraction can occur even around an object. A good example of this is half-plane diffraction, where the lightened side is just bright, but the shadow side still exhibits extra radiance from the bending of the light or even wave-like oscillation under certain conditions. This is different from umbras and penumbras. Took a while to find an example of this effect since most diffraction examples are about apertures and slits, which I feel like is better termed as ‚Äúthrough an object.‚Äù</p></div><div id="ref-veachthesis" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">E. Veach, <span>‚ÄúRobust monte carlo methods for light transport simulation,‚Äù</span> PhD thesis, Stanford University, Stanford, CA, USA, 1998.</div>
</div><div id="fn3"><p><sup>3</sup>&nbsp;There also exists a similarly theory called special relativity, which is a specific case of general relativity. You can read more about here on <a href="https://www.damtp.cam.ac.uk/user/tong/relativity.html">¬ß7</a> of the lecture notes. But basically we assume no gravity (hence, no force, no curvatures, and constant velocities) and focus on the spacetime nature of extreme cases in classical physics (e.g., perceived time at light speed).</p></div></div><p>So, I guess a quick teaser (for me and you) with a demo, I will first create a point of singularity and a light path unaffected by it. What would a light path affected by gravitational force be like? We first need to know the theory behind gravity, and currently there are practically only two out there: Newton‚Äôs law (for most use cases) and general relativity <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> (for exotic cases). You can probably guess which theory contains the black hole.</p>
<p>I started with <a href="https://www.damtp.cam.ac.uk/user/tong/gr.html">¬ß6: Black Holes</a>, which says there are multiple kind of black holes with the Schwarzschild black hole being the simplest of all. However, this section mostly discuss about proving and understanding the various properties of many kinds of black holes, which will only be useful later on (beyond the scope). <a href="https://www.damtp.cam.ac.uk/user/tong/gr.html">¬ß1.3.5: Light Bending</a> is what we care right now, discussing how light bends under Schwarzschild metric (i.e., the foundation for Schwarzschild black hole). By equation 1.54, we get the trajectory of our light ray affected by the gravitational force to be <span class="math inline">\(\frac{d^2u}{d\phi^2}+u=\frac{3GM}{c^2}{u^2}\)</span>, where <span class="math inline">\(u(\phi)=\frac{1}{r(\phi)}\)</span> is the inverse polar radius, <span class="math inline">\(G\)</span> is Newton‚Äôs gravitational constant (it appears again!), and <span class="math inline">\(M\)</span> is the mass of our object <em>warping</em> the light path <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. I will quickly demo this by evaluating the ODE numerically via Euler‚Äôs method.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Recall that light has no mass (i.e., null geodesic), so technically it is not orbiting around the black hole, but just following the spacetime frame itself that‚Äôs getting curved by the black hole.</p></div></div><p>I first need to rewrite the second-order ODE <span class="math inline">\(\ddot{u}+u=\frac{3GM}{c^2}{u^2}\)</span> (with <span class="math inline">\(\phi\)</span> as our independent variable) into a systems of first-order ODE for Euler‚Äôs method. <span class="math display">\[
\begin{cases}
\dot{u}=v \\
\dot{v}=\frac{3GM}{c^2}{u^2}-u \\
\end{cases}
\]</span></p>
<div>
<div id="pyodide-1" class="exercise-cell">

</div>
<script type="pyodide-1-contents">
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
</script>
</div>
<p>Additional ideas:</p>
<ul>
<li>Gravitational lensing (general case of black holes)</li>
<li>Wormholes</li>
<li>Collision of two black holes</li>
<li>Red shift</li>
<li>Relativistic distortion (i.e., camera near the black holes)</li>
<li>Accretion disk</li>
<li>Spinning black holes</li>
<li>Can we use differentiable rendering on an image of a black hole to estimate various parameter of it (e.g., mass)?
<ul>
<li>Just out of curiosity (there‚Äôs definitely a better way)</li>
</ul></li>
</ul>
<p>Topics to review:</p>
<ul>
<li>Differential Geometry</li>
<li>General Relativity</li>
<li>Non-euclidean geometry</li>
<li>Numerical ‚Äúsolution‚Äù to ODE</li>
</ul>
<p>Personal opinion: this is very different from the stuff I have done before and feels refreshing, but the math behind it is daunting at the same time.</p>
<p>Where graphics and astrophysics meet: <a href="https://arxiv.org/pdf/1502.03808">paper link</a></p>
</section>
<section id="rendering-exotic-light-sources-cold-cathode-fluorescent-displays-ccfds" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="rendering-exotic-light-sources-cold-cathode-fluorescent-displays-ccfds">Rendering exotic light sources: cold-cathode fluorescent displays (CCFDs)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../img/blog/40_ccfds.jpg" class="img-fluid figure-img"></p>
<figcaption>Nixie Tubes</figcaption>
</figure>
</div>
<p>I am a big fan of retro technologies, especially the warm neon lights of the bygone days. A year ago, I bought this (it‚Äôs a bit pricey) just out of fascination of what it looks like in real life. Unfortunately, it has this distinctive blue overtone which is missing when taking a photo with a consumer device (which makes it all of more interesting). Now, I‚Äôm curious if it‚Äôs possible to replicate this warm fuzzy feeling of a Nixie tube into computer rendering. There are three approaches to this with increasing level of complexity: emissive solid (i.e., a mesh with an emissive material), emissive participating media, or physically accurate simulation of CCFDs. I‚Äôll mostly be approaching it from the emissive participating media and a bit of physically-accurate modelling (i.e., physically-plausible CCFDs).</p>
<p>So how does one go about rendering the warm tone of CCFDs? Are they even always in an orange tone? How do they work? I‚Äôve came across this <a href="https://groups.google.com/g/neonixie-l/c/Z116Cv9AGpY">Google Group</a> discussing about a book ‚ÄúCold Cathode Glow Discharge Tubes‚Äù, by GF Weston from 1968, available in <a href="https://drive.google.com/drive/folders/1-i1uv20HFjT5RMy1ePGIwAyMcbMA-6sv">PDF</a> which has a wealth of information in how CCFDs work and their physical properties. Unfortunately, there were not a lot of discussion in optical properties (of this book and elsewhere I can find) that are important in rendering CCFDs. It is most likely because these electrical discharges (hence, light) from excited gasses produce all sorts of colors that are very sensitive to various parameters such as gas pressure, cathode-anode distance, voltage, amperage, gas composition, material used in for cathodes/anodes, etc. Since I‚Äôm not here to physically simulate what CCFDs would look like from these various parameters, I‚Äôll be focusing on Nixie tubes (which has more information usually) and maybe a limited range of parameters (it‚Äôs still interesting to see how CCFDs would evolve over certain parameters).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../img/blog/40_diagram.png" class="img-fluid figure-img"></p>
<figcaption>Fig 3.2 of ‚ÄúCold Cathode Glow Discharge Tubes‚Äù</figcaption>
</figure>
</div>
<p>CCFDs can just be an emissive participating media with an assigned color of orange, but that‚Äôs no fun, since there are also various color overtones it produces depending on the gas composition that would be missing. Hence, I am having the input to just be the gas composition and some basic geometric model of the energy field (i.e., the emission surrounding the shape of the cathode or the cathode sheathed in a layer of emission<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>). Unfortunately, it seems like most Nixie Tube discussion lack the information on their visual properties. So, we turn to the physics of light in hopes of simulating the same physically correct emission of gas composition like shown in the picture. To get there, we need to know some radiative transfer theory, which is readily talked about in <span class="citation" data-cites="pharr2023physically"><a href="#ref-pharr2023physically" role="doc-biblioref">[6, Ch. 11]</a></span> for volumetric scattering process and more completely in <span class="citation" data-cites="pharr2023physically"><a href="#ref-pharr2023physically" role="doc-biblioref">[6, Ch. 14]</a></span> with the introduction of the radiative transfer equation.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;Sometimes, the negative glow is shown sticking onto the cathode. In other times, we have two dark spaces with three regions of emission from the cathode side (before the Faraday dark space). The geometries of emission can be quite sensitive, so we will assume the ‚Äúnegative glow‚Äù is sticked/sheathed onto the cathode.</p></div><div id="fn6"><p><sup>6</sup>&nbsp;As I look into this &amp; the Nixie Tubes more, there are many more physical abstraction you can uncover (e.g., electrical glow discharge, fluorescent bulbs, anisotropic absorption/out-scattering, etc.), which at a certain point, you‚Äôre just modelling electromagnetic waves themselves. In my opinion, we model the most physically-grounded renderer as much as possible while also keeping it fast, so given some known discrete scene parameters, we can render a realistic image in a computationally-sensible way. I hope this is what graphics is all about.</p></div></div><p>In computer graphics, rendering volumetric effects requires us to at least model three main <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> physical process: absorption, emission, and scattering (further broken down as in-scattering and out-scattering). By assumption, we model these effects as differential equations (ordered as emission, absorption, out-scattering, and in -scattering):</p>
<p><span class="math display">\[
\begin{align}
dL_o(\mathbf{x},\mathbf{\omega}) &amp;= \sigma_a(\mathbf{x},\mathbf{\omega}) L_e(\mathbf{x},\mathbf{\omega})dt \\
dL_o(\mathbf{x},\mathbf{\omega}) &amp;= -\sigma_a(\mathbf{x},\mathbf{\omega}) L_i(\mathbf{x},-\mathbf{\omega})dt \\
dL_o(\mathbf{x},\mathbf{\omega}) &amp;= -\sigma_s(\mathbf{x},\mathbf{\omega}) L_i(\mathbf{x},-\mathbf{\omega})dt \\
dL_o(\mathbf{x},\mathbf{\omega}) &amp;= \sigma_s(\mathbf{x},\mathbf{\omega})\int_{S^2} p(\mathbf{x},\mathbf{\omega},\mathbf{\omega}_i)L_i(\mathbf{x},\omega_i)d\omega_i dt \\
\end{align}
\]</span></p>
<p>where <span class="math inline">\(dL_o(\mathbf{x},\mathbf{\omega}):=L_o(\mathbf{x}+\mathbf{\omega}dt, \mathbf{\omega})\)</span> and <span class="math inline">\(L_o(\mathbf{x},\mathbf{\omega}):=L_i(\mathbf{x},-\mathbf{\omega})\)</span> (remember that we are only traversing the volumetric media in a straight line to simplify our model).</p>
<p><span class="math inline">\(\sigma_a\)</span> is the absorption coefficient and <span class="math inline">\(\sigma_s\)</span> is the extinction coefficient, and <span class="math inline">\(p\)</span> is the phase function‚Äîthe BSDF reciprocal of volumetric scattering.</p>
<p>So, if we rewrite the formulas, the combined differential change in radiance at a point <span class="math inline">\(\mathbf{p}'=\mathbf{p}+t\mathbf{\omega}\)</span> in a volumetric media is <span class="math inline">\(\frac{d}{dt}L_o(\mathbf{p}',\mathbf{\omega})=-\sigma_t(\mathbf{p}',\mathbf{\omega})L_i(\mathbf{p}',-\mathbf{\omega})+\sigma_t(\mathbf{p}',\mathbf{\omega})L_s(\mathbf{p}',\mathbf{\omega})\)</span>. The <span class="math inline">\(\sigma_t=\sigma_a+\sigma_s\)</span> is the extinction/attenuation coefficient, and in this case it can be interpreted as the medium‚Äôs density, where larger value means more effect from the medium while lower value means less effect (i.e., transparent air). Notably, the first term includes the transmittance, which can be analytically <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> solved into <span class="math inline">\(e^{-\sigma_t d}\)</span> where <span class="math inline">\(d\)</span> is the distance <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Additionally, in <span class="citation" data-cites="pharr2023physically"><a href="#ref-pharr2023physically" role="doc-biblioref">[6]</a>, Equation 11.10</span>, they mysteriously used the indirect <span class="math inline">\(T_r(\mathbf{p}+t\omega\to\mathbf{p}')\)</span> instead of the more direct <span class="math inline">\(T_r(\mathbf{p}\to\mathbf{p}+t\omega)\)</span>, but are equivalent with a change of variable. This can be thought of finding the optical depth/thickness from <span class="math inline">\(0\to t\)</span> or remainder of the optical thickness from <span class="math inline">\(t \to d\)</span> (the inner transmission integral).</p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Assuming homogenous media (i.e., constant density).</p></div><div id="fn8"><p><sup>8</sup>&nbsp;This is better known as the <em>exponential</em> volumetric transport, which is commonly seen in NeRF and NeuS. A natural question to ask is whether <em>non-</em>exponential volumetric transport exist? In fact, it does. The volumetric transport we, and the book, implicitly assume is the Beer-Lambert law., whereas non-exponential version opens a whole can of worms. Both all are governed by the generalized radiative transfer equation (RTE).</p></div><div id="ref-pharr2023physically" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">M. Pharr, W. Jakob, and G. Humphreys, <em>Physically based rendering, fourth edition: From theory to implementation</em>. MIT Press, 2023. Available: <a href="https://books.google.ad/books?id=kUtwEAAAQBAJ">https://books.google.ad/books?id=kUtwEAAAQBAJ</a></div>
</div><div id="fn9"><p><sup>9</sup>&nbsp;As usual, we assume each <span class="math inline">\(N\)</span>-length path has a single emission source at the end, but <span class="math inline">\(N\)</span> can vary from various sampled paths. Just makes the math cleaner without restricting anything.</p></div></div><p>To actually render volumetric effect, we need a volumetric integrator that generalizes the volumetric scattering effect as a path -integral formulation. The general idea is simple: we just generalize the formulation where the domain include medium locations instead of just surface locations and the measure extended to measure positions of volumetric effect. The contribution function is extended to support phase functions (i.e., in-scattering effects), transmittance (i.e., absorption and out-scattering), and emission <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<p><img src="../img/blog/40_clouds.jpg" class="img-fluid"></p>
<p>As I‚Äôm writing this out, I also realized clouds is another form volumetric media I want to see it work. Not just a static cloud, but like maybe some procedural noise or even a simple fluid simulation going to see the clouds grow and shrink over time.</p>
<p>Additional ideas:</p>
<ul>
<li>Fluid simulation of clouds?</li>
<li>Accurately render the emission spectrum described from a molecular composition?</li>
</ul>
<p>Topics to review:</p>
<ul>
<li>Radiative transfer equation (RTE)</li>
<li>Beer‚Äôs Lambert Law</li>
<li>Fluid dynamics</li>
<li>Sampling volumetric light transports</li>
</ul>
<p>Personal opinion: I think this follows more on traditional computer graphics for good reason, volumetric media is common and knowing it is useful (and it‚Äôs also fun).</p>
<p>Originally wanted to model some exotic light sources, but realized they are quite a complex physical process. This section (i.e., the topic) is probably more aptly named as volumetric light transport. Good thing I did this so I have a better idea what the project could look like.</p>
</section>
<section id="stochastic-geometry" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="stochastic-geometry">Stochastic geometry</h2>
<p>As if probability (or this notion of probabilistic stuff) wasn‚Äôt enough, stochasticity (or stochastic stuff) is this new kid down the street I have been hearing quite frequently (apart from stochastic gradient descent). Let us answer first on what is stochasticity, and how is it different from ‚Äúprobabilistic‚Äù?</p>
<p>According to Merriam-Webster, for something to be stochastic, it means the something involves a random variable, chance, or probability, which actually is just ever more slightly specific then the term ‚Äúprobabilistic.‚Äù In other words, they‚Äôre quite same. However, from my initial understanding, people <em>generally</em> associate probabilistic model as something that emphasizes more on learning and inference, whereas stochastic model emphasizes more on modelling the randomness (to a certain degree) of what otherwise would be a mostly deterministic <em>evolutionary</em> process over time, space, or any other indexable/ordered objects (i.e., stochastic process).</p>
<p>Now the phrase ‚Äústochastic geometry‚Äù should be a bit clearer now, let‚Äôs just dive what‚Äôs all the buzz with this in these two papers: <span class="citation" data-cites="Miller:VOS:2024"><a href="#ref-Miller:VOS:2024" role="doc-biblioref">[7]</a></span> and <span class="citation" data-cites="seyb24from"><a href="#ref-seyb24from" role="doc-biblioref">[8]</a></span>. <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> Remember, we should always be asking ourselves whether this ‚Äústochastic geometry‚Äù is bringing us benefits in one or both aspects while maintaining at least one other aspect: computationally practicality (on current or near future processors) and physically-correct appearances <a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;Actually, the more I‚Äôm reading this two papers, the more I am grateful that I have covered volumetric light transport firstüòÖ. (Hinting on whats coming up.)</p></div><div id="fn11"><p><sup>11</sup>&nbsp;If we only want physically-correct appearances, we might as well have all the supercomputers in the world to handle all the complex physical phenomenon (which actually uses a ton of statistics for a long time already). If we only want computational practicality, we have rasterization (e.g., vanilla Minecraft, Roblox, Terraria, etc.).</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="../img/blog/40_stoch_geom_0.png" class="img-fluid figure-img"></p>
<figcaption>Fig 1. from <span class="citation" data-cites="Miller:VOS:2024"><a href="#ref-Miller:VOS:2024" role="doc-biblioref">[7]</a></span></figcaption>
<div class="no-row-height column-margin column-container"></div></figure>
</div>
<p><span class="citation" data-cites="Miller:VOS:2024"><a href="#ref-Miller:VOS:2024" role="doc-biblioref">[7]</a></span> focused on generalizing the exponential volumetric transport to solid media to explain how recent works in signed distanced fields <a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> have been successful in modelling opaque, solid geometries as stochastic participating media.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;SDFs requires some sort of volumetric transport to be rendered directly. There are also marching cubes to convert SDFs into meshes.</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="../img/blog/40_stoch_geom_1.png" class="img-fluid figure-img"></p>
<figcaption>From <span class="citation" data-cites="seyb24from"><a href="#ref-seyb24from" role="doc-biblioref">[8]</a></span></figcaption>
<div class="no-row-height column-margin column-container"></div></figure>
</div>
<p>Their novelty is mainly in developing an efficient rendering algorithm for a new type of scene representations. While this efficient algorithm is lathered with technical details, the background of their work is interesting: bringing stochasticity into scene geometry to unify all representations into one, which traditionally has a collection of specialized models to render certain geometries (usually surfaces and participating media). This new generalization naturally gives us geometries that are in between the participating media and surfaces known as ‚Äúmesoscale‚Äù geometries. I hope this allows us to additionally model certain appearances in the physical world that would otherwise be difficult (i.e., larger parameter space that fits closer to physically-correct models).</p>
<p>While both papers uses the same particular interpretation of stochastic geometry, known as stochastic implicit surfaces (SIS) via signed distance functions (SDF), <span class="citation" data-cites="Miller:VOS:2024"><a href="#ref-Miller:VOS:2024" role="doc-biblioref">[7]</a></span> emphasizes on one particular case where opaque solids are represented as stochastic participating media due to the rise of NeuS (and indirectly via NeRF), whereas <span class="citation" data-cites="seyb24from"><a href="#ref-seyb24from" role="doc-biblioref">[8]</a></span> attempts to further generalize all classes of geometries onto a continuum that allows exploration of new materials (that could potentially be useful for physically-correct geometric modelling).</p>
<div class="no-row-height column-margin column-container"><div id="ref-Miller:VOS:2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">B. Miller, H. Chen, A. Lai, and I. Gkioulekas, <span>‚ÄúObjects as volumes: A stochastic geometry view of opaque solids,‚Äù</span> in <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</em>, 2024, pp. 87‚Äì97.</div>
</div><div id="ref-seyb24from" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">D. Seyb, E. d‚ÄôEon, B. Bitterli, and W. Jarosz, <span>‚ÄúFrom microfacets to participating media: <span>A</span> unified theory of light transport with stochastic geometry,‚Äù</span> <em>ACM Transactions on Graphics (Proceedings of SIGGRAPH)</em>, vol. 43, no. 4, Jul. 2024, doi: <a href="https://doi.org/10/gt5nh9">10/gt5nh9</a>.</div>
</div></div><p>Topics to review:</p>
<ul>
<li>Volumetric light transports</li>
<li>Stochastic process</li>
</ul>
<p>Personal opinion: This seems interesting to me where we incorporate randomness into opaque solid geometries. In reality, this idea has sort of been implicitly used in a lot of places already (e.g., NeuS) and mostly serves as a theoretical interest. But if we see stochastic geometry as a way to generalize material models, I think this is something cool to see it work on a toy example.</p>
</section>
<section id="re-formulating-problems-as-light-transport" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="re-formulating-problems-as-light-transport">Re-formulating problems as light-transport</h2>
<p>It is always interesting to see how other problem domains can be reduced to a light transport problem (or to any problem in general), since you get to explore and understand what are the fundamental properties of light transports that would be useful to find the solution. Additionally, you would probably have to figure out what are the underlying assumption needed to enables these structure for finding potential solutions. Currently, there are two notable domains of problems that fits well into light-transport: inverse rendering (via differentiable rendering) and PDE solvers.</p>
<section id="inverse-rendering" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="inverse-rendering">Inverse Rendering</h4>
<p>Rendering <span class="math inline">\(f\)</span> is all about capturing lights from known scene description <span class="math inline">\(\theta\)</span> into images <span class="math inline">\(I\)</span> right <a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>? <span class="math inline">\(I=f(\theta)\)</span></p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;As mentioned in the <a href="#path-space-differentiable-rendering-(psdr)">first section</a></p></div></div><p>Camera <span class="math inline">\(C\)</span> is all about capturing lights via <em>real</em> physical process from <em>un</em>known scene description <span class="math inline">\(\phi\)</span> into images <span class="math inline">\(I'\)</span> right? <span class="math inline">\(I'=C(\phi)\)</span></p>
<p>What if we want to find the <em>unknown</em> <span class="math inline">\(\phi\)</span>?</p>
<p>If <span class="math inline">\(f\approx C\)</span> <a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>, we can minimize the difference between the two images via optimization to find the optimal scene description <span class="math inline">\(\theta\)</span> that best estimates <span class="math inline">\(\phi\)</span>, where <span class="math inline">\({\arg\min}_\theta I-I'={\arg\min}_\theta f(\theta)-C(\phi)\)</span>. This requires differentiating the <em>rendering process</em> with respect to <span class="math inline">\(\theta\)</span>, allowing us to piggy-back on years of development on tools developed from forward physically-plausible rendering into inverse rendering.</p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;In other words, we assume that our synthetic rendering process <span class="math inline">\(f\)</span> is able to model most light phenomenon accurately, almost like <span class="math inline">\(C\)</span>.</p></div></div></section>
<section id="pde-solvers" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="pde-solvers">PDE solvers</h4>
<p>Whenever I think of solving anything about differential equations, I just think of the common examples given from classes: Newton‚Äôs law of cooling or the logistic growth models (maybe for good reason??). But in PDEs, solutions are much more interesting to think about and visualize since a large part of is solving them numerically<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>. Common methods includes finite element method (FEM) and boundary element method (BEM), but they all have tradeoffs, especially when we want to query a value in the interior. However, we can use Walk on Spheres to find the value more efficiently from the principles of light transport and computer graphics.</p>
<div class="no-row-height column-margin column-container"><div id="fn15"><p><sup>15</sup>&nbsp;Actually, there‚Äôs some interesting analytical solutions and analysis in ODEs/PDEs such as Laplace and Fourier transformation.</p></div><div id="ref-Sawhney:2024:MCGP" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">R. Sawhney and B. Miller, <span>‚ÄúMonte carlo geometry processing,‚Äù</span> in <em>SGP 2024 graduate school courses</em>, 2024.</div>
</div></div><p>There‚Äôs an online course that talks about this more in-depth: <span class="citation" data-cites="Sawhney:2024:MCGP"><a href="#ref-Sawhney:2024:MCGP" role="doc-biblioref">[9]</a></span>.</p>
</section>
<section id="any-others" class="level4">
<h4 class="anchored" data-anchor-id="any-others">Any others?</h4>
<p>It is likely that I will have to play around other orthogonal subjects that interests me and see if there are any problems in there that can be reduced to a light transport.</p>
</section>
</section>
</section>
<section id="d-vision" class="level1 page-columns page-full">
<h1>3D Vision</h1>
<section id="neural-3d-reconstructiongeneration" class="level2">
<h2 class="anchored" data-anchor-id="neural-3d-reconstructiongeneration">Neural 3D Reconstruction/Generation</h2>
<p>3DGS sounded very cool at first, but you would realize soon enough that they are more for novel-view synthesis, because at the end of the day, they are still a point cloud. Though this is changing fast also. From their pipeline, I guess one thing that still intrigues me is how they do the adaptive density control. A lot of them are heuristics, but two main ones are under-reconstruction and over-reconstruction, both derived from view-space positional gradients (i.e., what direction should the original gaussian move to minimize the error). If the gaussian is small and in under-reconstructed region, they just make a clone and move it along the original gaussian splat‚Äôs view-position gradient. If the gaussian has a high-variance and is in over-reconstructed region, then just use the original gaussian as PDF for sampling the next two gaussian‚Äôs position with smaller size.</p>
<p>The problem of Structure from Motion is how can we estimate camera poses and world geometry (usually point clouds) just from <em>images</em>? Remember, a lot models relies on this for their training, such as NeRFs and 3DGS. Hence, it is of great interest.</p>
<ul>
<li>Traditional (old): COLMAP</li>
<li>Mixed (new): Dust3r, Mast3r, VGGSfM</li>
<li>Full ML (latest): VGGT</li>
</ul>
<p>With the recent release of VGGT, it is awesome to see 3D reconstruction working purely from a feed-forward network with minimal pre-processing and post-processing.</p>
<p>Another intriguing problem are generative models that generate 3D data, especially from a single view and via diffusion. I will have to look more papers about 3D estimation from a single-view.</p>
</section>
<section id="diffusion-models-stochastic-differential-equations-sdes" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="diffusion-models-stochastic-differential-equations-sdes">Diffusion Models &amp; Stochastic Differential Equations (SDEs)</h2>
<p>The general idea is that this is a generative model that is able to spatially generate realistic 2D images unconditionally or conditionally (e.g., text prompt, image prompt, etc.). It does this clever trick where it repeatedly adds noise to the training images until it becomes <em>indistinguishable</em> to fully random images, but the model is trained on these noises to denoise them later. So on the next time (i.e., inference-time), you feed it a random image and it will denoise it to look realistic learnt from the training dataset. There are many great resources to learn diffusion models now. In particular, if I do get the time, I plan to read <span class="citation" data-cites="prince2023understanding"><a href="#ref-prince2023understanding" role="doc-biblioref">[10, Ch. 17‚Äì18]</a></span> and the original <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf">DDPM paper</a>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-prince2023understanding" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">S. J. D. Prince, <em>Understanding deep learning</em>. The MIT Press, 2023. Available: <a href="http://udlbook.com">http://udlbook.com</a></div>
</div></div><p>In the most recent survey paper on diffusion models <a href="https://arxiv.org/pdf/2502.06805">here</a>, there‚Äôs an interesting connection between the diffusion process and SDEs. ODEs/PDEs are useful when modeling from a set of rules (i.e., equations) of a dynamic system, which we solve the true underlying function analytically or numerically via simulations. Sometimes, these dynamic systems can have some random process (e.g., diffusion noise) term incorporated, resulting in stochastic differential equations.</p>
<p>Additional ideas:</p>
<ul>
<li>Diffusion models on 3D geometries</li>
<li>Code or video animation of SDEs (since they‚Äôre inherently an evolutionary process of a dynamic system, this is probably the best way for visualization)</li>
</ul>
<p>Topics to review:</p>
<ul>
<li>Stochastic process</li>
<li>Stochastic differential equations</li>
<li>Stochastic calculus</li>
</ul>
</section>
<section id="bundle-adjustment-ba-lie-algebra" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="bundle-adjustment-ba-lie-algebra">Bundle Adjustment (BA) &amp; Lie Algebra</h2>
<p>I have always thought Bundle Adjustment was small, simple thing in SfM<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>, until I started coming across in the original ORB-SLAM paper and mentions some foreign concepts such as Lie Algebra. Lie (pronounced Lee) Algebra is interesting in that it has a geometric intuition from differential geometry, but also has an associated Lie Group (from group theory). However, Lie Algebra is commonly talked in relation to robotics state estimation in the <a href="http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser24.pdf">book</a> and the <a href="https://arxiv.org/pdf/1812.01537">paper</a>. Regardless, these are some pointers that seems to be a good resource to get started.</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;It‚Äôs the last process that goes by pretty fast usually. And this idea of ‚Äúadjustment‚Äù didn‚Äôt really do some justice since it just evokes a small algorithm that nudges parameter to achieve something that‚Äôs a tad bit more optimal to make the estimations more polished and nice (which it does, but much more complex).</p></div></div><p>For bundle adjustment, the key idea is that we already have a rough estimation from previous estimates (or just randomly initialize it a super bad state). Then, BA attempts to <em>globally</em> adjust and refine both the camera pose and point locations to produce a higher quality reconstruction. This <a href="https://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Triggs00.pdf">classical survey</a> talks how one implements BA in-depth, while this <a href="https://arxiv.org/pdf/1912.03858">modern survey</a> attempts to optimize BA in a distributed manner.</p>
<p>Additional ideas:</p>
<ul>
<li>Code or video animation of the optimization process</li>
</ul>
<p>Topics to review/prepare:</p>
<ul>
<li>Non-linear optimization
<ul>
<li>Levenberg‚ÄìMarquardt</li>
</ul></li>
<li>Lots of linear algebra tricks</li>
<li>Lie algebra + groups (why not)</li>
</ul>
</section>
<section id="fast-fourier-transform-fft" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="fast-fourier-transform-fft">Fast Fourier Transform (FFT)</h2>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://visionbook.mit.edu/figures/Image_processing_fourier/dft_b.png" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="foundationsCVbook"><a href="#ref-foundationsCVbook" role="doc-biblioref">[11, Fig. 16.8]</a></span></figcaption>
<div class="no-row-height column-margin column-container"></div></figure>
</div>
<p>First of all, what is fourier transform? It converts raw signals (i.e., time domain) into an amplitude function of frequency (i.e., frequency domain). In the <span class="citation" data-cites="foundationsCVbook"><a href="#ref-foundationsCVbook" role="doc-biblioref">[11, Ch. 15‚Äì16]</a></span>, they talk more rigorously on how it works, specifically discrete fourier transform in the context of spatial 2D image signals.</p>
<div class="no-row-height column-margin column-container"><div id="ref-foundationsCVbook" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">A. Torralba, P. Isola, and W. T. Freeman, <em>Foundations of computer vision</em>. in Adaptive computation and machine learning series. MIT Press, 2024. Available: <a href="https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/">https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/</a></div>
</div></div><p>Fast fourier transform is an algorithm to automatically find the transformed signals automatically. It will be interesting if I just implement my own FFT and see the various frequency that automatically pops out and an attempt to reconstruct it signal by signal.</p>
<p>This also reminds of spherical harmonics. Since they also use complex exponentials, maybe there‚Äôs some connection there?</p>
<p>Topics to review/prepare:</p>
<ul>
<li>Discrete fourier transform</li>
<li>FFT algorithm</li>
</ul>
</section>
<section id="applications-of-3d-vision-graphics" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-3d-vision-graphics">Applications of 3D Vision + Graphics</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://worldmodels.github.io/assets/world_model_comic.jpeg" class="img-fluid figure-img"></p>
<figcaption>World model. Sourced from <a href="worldmodels.github.io">here</a></figcaption>
</figure>
</div>
<p>One particular applications of 3D vision and graphics that is interesting right now is visuomotor and generative world models, combining all three disciplines from robotics (specifically autonomous agents) and perception (i.e., vision with sensor fusion) to reinforcement learning. The applications for both of them definitely leans more on the frontier/novel side of things, but it would be interesting to see it used in more classical settings (because <em>why not</em>).</p>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>Honestly, I definitely rushed some on some of the later topics, but it‚Äôs good enough to better understand what undertaking each of these project would be like. Some of them could easily be treated like an entire course. Regardless, I should keep each exploration of the subjects as many small blogs rather than this one giant blog of many subjects.</p>


<script type="pyodide-data">
eyJvcHRpb25zIjp7ImVudiI6eyJQTE9UTFlfUkVOREVSRVIiOiJwbG90bHlfbWltZXR5cGUifSwiaW5kZXhVUkwiOiJodHRwczovL2Nkbi5qc2RlbGl2ci5uZXQvcHlvZGlkZS92MC4yOC4xL2Z1bGwvIn0sInBhY2thZ2VzIjp7InBrZ3MiOlsicHlvZGlkZV9odHRwIiwibWljcm9waXAiLCJpcHl0aG9uIl19fQ==
</script>
<script type="ojs-module-contents">
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
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>

</section>


</main> <!-- /main -->
<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../blog";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>